---
layout: bt_wiki
title: Scaling Rules
category: Developing Recipes
publish: true
abstract: Describes the Scaling Rules mechanism and usage
pageord: 1200
---

h2. Scaling services

Cloudify supports two methods for scaling a service:
# "Automatic Scaling":#as
# "Manual Scaling":#ms


h2(#as). Automatic Scaling (Scaling Rules)

Cloudify enables each service to define one scaling rule for deciding whether the service needs to scale out or scale in. For example, using a rule based on the average number of busy threads, Cloudify can decide to increase or decrease the number of tomcat service instances.

h3. The Scaling Rule Flow

<img src="../../images/recipes/scale_rule_flow.jpg" width="536" height="407"/>

h3. The Scaling Rule's Elements

Scaling rules have upper and lower thresholds based on statistical metrics defined in the recipe and collected from the application's services by plugins. Each rule relates to a cluster that contains one or more service instances.

* The following *metrics* (measurable components) are available:
** Any custom KPI(Key Performance Indicator)--For example: JMX attributes
** Sampling rates--For example: the number of requests per second.
* The following *statistics* (interpretation of data) are available: 
** Avg/min/max/percentile
** Time range

Thus statistical metrics used by rules are the interpretation of the metrics collected. When a statistical metric is above the upper threshold, Cloudify increases the number of provisioned service instances, and conversely when it is below the lower threshold, Cloudify decreases the number of provisioned service instances.

For example, if a service has 3 service instances, and the CPU usage metric collected from the service instances are 30%, 20% and 90% respectively. If the rule defines an upper threshold for the CPU usage as 80% based on the Max statistic, then in this example the statistical metric [Max(30, 20, 90) == 90] would cause Cloudify to provision another service instance.

h3. Scaling rules syntax

Here is a snippet from a recipe that adds one tomcat instance, if at least one tomcat instance has more than 1 request per second. Conversely, it removes one tomcat instance, if the tomcat cluster (all the tomcat instances) has less than 0.2 requests per second.

<script src="https://gist.github.com/2566833.js?file=tomcat_auto_scaling.groovy"></script>
h4(info). In the current version, you can only describe one scaling rule per service.

h2(#ms). Manual Scaling

Cloudify also enables you to set the number of service instances manually.
To set the number of service instances manually, at the Cloudify shell prompt, type: *@set-instances@* @service-name number-of-required-instances@. 
h4(impt). The value of @number-of-required-instances@ must be:
<ol><li>greater than or equal to the value of *@minAllowedInstances@*, and</li>
<li>less than or equal to the value of *@maxAllowedInstances@*</li></ol>
described in the service descriptor file.

h4(impt). To enable manual scaling, you must set the *@elastic@* attribute to @true@ in the service descriptor file.

The following example show the command to adjust the number of tomcat service instances to three: *@set-instances@* @tomcat 3@

h4(info). If the tomcat service has *two* instances prior to invoking the command, it *increases* the number of tomcat service instances to three. Conversely, if the tomcat service has *five* instances prior to invoking the command, it *decreases* the number of tomcat service instances to three.

The following shows an example service section describing the attributes required for manual scaling.
<script src="https://gist.github.com/2567663.js?file=tomcat_manual_scaling.groovy"></script>